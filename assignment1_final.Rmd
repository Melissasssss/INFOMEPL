---
title: "Lab assignment 1: t-tests, linear regression, analyzing lexical decision task"
author: "INFOMEPL"
date: "Deadline: Tuesday, February 27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(dplyr)
library(ggplot2)

itemdata <- read.csv("MALD1_SelectedItemData.csv", sep="\t")
# This data frame stors information about items
str(itemdata)
head(itemdata)

responsedata <- read.csv("MALD1_SelectedResponseData.csv", sep="\t")
# This data frame stors information about participants' responses
str(responsedata)
head(responsedata)

```


### Q1: Merge data and report basic information

Merge the two data frames (responsedata and itemdata) into one data frame. Afterwards, report descriptive summaries for the whole dataset and also separately for Subjects 15351, 16854 and 170373. Report summaries of the following measures:

1. Reaction times (RT)
2. Frequencies (use FreqCOCAspok, which is a spoken corpus of American English). 
3. RT for words and pseudowords separately. Use the variable IsWord: when it is TRUE, the word is a real word, when it is FALSE it is a pseudoword. 

For descriptive summaries it is enough you report means and spread of data - e.g., variances or standard deviations, or just a range of data. You can also provide histograms (for example, by replicating the code we have above; for RTs this is already done).

```{r}

# Hint: try to use dplyr and a family of join functions,  and group_by and summarise from the same package.
# Of course, other functions might be useful and needed.

# Check help of these functions and check dplyr for details.

# Merge data frames by item column which belongs to both data frames
merged_data <- merge(responsedata, itemdata, by = "Item")

# Overall descriptive summaries OLD WAY, gave error
# overall_summaries <- merged_data %>%
#   summarise(
#     MeanRT = mean(RT, na.rm = TRUE),
#     SdRT = sd(RT, na.rm = TRUE),
#     RangeRT = range(RT, na.rm = TRUE),
#     MeanFreqCOCAspok = mean(FreqCOCAspok, na.rm = TRUE),
#     SdFreqCOCAspok = sd(FreqCOCAspok, na.rm = TRUE),
#     RangeFreqCOCAspok = range(FreqCOCAspok, na.rm = TRUE)
#   )

# Overall descriptive summaries using range function to only get 1 row per summaries group
overall_summaries <- merged_data %>%
  summarise(
    MeanRT = mean(RT, na.rm = TRUE),
    SdRT = sd(RT, na.rm = TRUE),
    MinRT = min(RT, na.rm = TRUE),
    MaxRT = max(RT, na.rm = TRUE),
    MeanFreqCOCAspok = mean(FreqCOCAspok, na.rm = TRUE),
    SdFreqCOCAspok = sd(FreqCOCAspok, na.rm = TRUE),
    MinFreqCOCAspok = min(FreqCOCAspok, na.rm = TRUE),
    MaxFreqCOCAspok = max(FreqCOCAspok, na.rm = TRUE)
  )

# RT for words and pseudowords
word_pseudoword_summary <- merged_data %>%
  group_by(IsWord) %>%
  summarise(
    MeanRT = mean(RT, na.rm = TRUE),
    SdRT = sd(RT, na.rm = TRUE),
    MinRT = min(RT, na.rm = TRUE),
    MaxRT = max(RT, na.rm = TRUE)
  )

# For specific subjects
subjects_summary <- merged_data %>%
  filter(Subject %in% c(15351, 16854, 170373)) %>%
  group_by(Subject) %>%
  summarise(
    MeanRT = mean(RT, na.rm = TRUE),
    SdRT = sd(RT, na.rm = TRUE),
    MinRT = min(RT, na.rm = TRUE),
    MaxRT = max(RT, na.rm = TRUE),
    MeanFreqCOCAspok = mean(FreqCOCAspok, na.rm = TRUE),
    SdFreqCOCAspok = sd(FreqCOCAspok, na.rm = TRUE),
    MinFreqCOCAspok = min(FreqCOCAspok, na.rm = TRUE),
    MaxFreqCOCAspok = max(FreqCOCAspok, na.rm = TRUE)
  )

# View the data frames
View(overall_summaries)
View(subjects_summary)
View(word_pseudoword_summary)

# Histogram for Response times (overall)
ggplot(merged_data, aes(x = RT)) +
  geom_histogram(binwidth = 100, fill = "blue", color = "black") +
  labs(title = "Histogram of Reaction Times", x = "Reaction Time (ms)", y = "Frequency") +
  theme_minimal()


```


### Q2: Implement Cohen's d and the calculation of t values

In answering this question, you are not allowed to use any R packages or R functions that implement Cohen's d or the calculation of t-tests. However, you can use such packages (for example, effsize for Cohen's d and t.test for t-values) to double-check that your function works correctly. In doing so, be careful - some implementations might slightly differ wrt how they calculate $s$, so you might not get exactly identical numbers. This is another reason why you should not just rely on another package in your answer. If you check, say, stackoverflow or use an AI tool like ChatGPT, you should also be careful -- there are various ways of implementing Cohen's $d$ and $t$ calculation and not all are equivalent to what we do here.

First, implement Cohen's $d$ as a function in R. That is, you have to fill in the body of the function (what is put in as...) that you have here below. As said above, it is enough to implement the simplified version (one in which the length of $x_1$ and $x_2$ is the same).

```{r}

# n1 and n2 should be equal
cohend <- function(x1, x2) {
  mean_x1 <- mean(x1)
  mean_x2 <- mean(x2)
  s <- sqrt((length(x1) - 1) * (var(x1) + var(x2)) / (2*length(x1) - 2))
  d <- (mean_x1 - mean_x2) / s
  return(d)
}
```

After the implementation, test your function and report collected Cohen's $d$ on four cases discussed below. Along with that, report whether the effect size is small, medium or large ($|d|<0.5$ is small, $|d|<0.8$ is medium, above that is large).
    
1. RTs for words and pseudowords for Subject numbered 15351.
2. RTs for words and pseudowords for Subject numbered 16854.
3. RTs for words and pseudowords for Subject numbered 170373.
4. RTs for all words and pseudowords.
5. RTs for the two vectors provided below as word\_15292 and pseudoword\_15292 (these are a few selected responses to words and pseudowords from subject 15292).

```{r}

subject_number <- 15351

# Get the response time for the word and pseudowords
words_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == FALSE) %>%
  pull(RT)

effect_size_classification <- function(d) {
  if(abs(d) < 0.5) {
    return("small")
  } else if(abs(d) < 0.8) {
    return("medium")
  } else {
    return("large")
  }
}


# 1.Calculate Cohen's d for 15351
# "Cohen's d for subject 15351 is -1.39943111730686 . Effect size is large ."
subject_number <- 15351

words_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == FALSE) %>%
  pull(RT)

d_value <- cohend(words_rt, pseudowords_rt)
effect_size <- effect_size_classification(d_value)

print(paste("Cohen's d for subject", subject_number, "is", d_value, ". Effect size is", effect_size, "."))

# 2.Calculate Cohen's d for 16854
#  "Cohen's d for subject 16854 is -0.171013812364667 . Effect size is small ."
subject_number <- 16854

words_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == FALSE) %>%
  pull(RT)

d_value <- cohend(words_rt, pseudowords_rt)
effect_size <- effect_size_classification(d_value)

print(paste("Cohen's d for subject", subject_number, "is", d_value, ". Effect size is", effect_size, "."))


# 3. Calculate Cohen's d for 170373
# "Cohen's d for subject 170373 is -0.343143399184897 . Effect size is small ."

subject_number <- 170373

words_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == FALSE) %>%
  pull(RT)

d_value <- cohend(words_rt, pseudowords_rt)
effect_size <- effect_size_classification(d_value)

print(paste("Cohen's d for subject", subject_number, "is", d_value, ". Effect size is", effect_size, "."))


# 4.For all words and pseudowords
# "Cohen's d for all words and pseudowords 170373 is -0.410810089564915 . Effect size is small ."
words_rt <- merged_data %>%
  filter(IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter( IsWord == FALSE) %>%
  pull(RT)

d_value <- cohend(words_rt, pseudowords_rt)
effect_size <- effect_size_classification(d_value)

print(paste("Cohen's d for all words and pseudowords", subject_number, "is", d_value, ". Effect size is", effect_size, "."))


# 5.Calculate Cohen's d for the 2 vectors

subject_number <- 15292
#  "Cohen's d for subject 15292 is 0 . Effect size is small ."
word_15292 <- c(2206, 1583, 1154, 1010,  865,  931, 1129,  683,  820, 1132, 1049, 1211, 1261, 957, 1058,  790,  851, 1908, 1504, 1400,  924)

pseudoword_15292 <- c(677,  949,  889,  881,  917,  769,  772,  922, 1944,  881,  976, 1087, 1252,  914, 1277,  825, 1295, 1336,  788,  885,  932)
d_value <- cohend(word_15292, word_15292)
effect_size <- effect_size_classification(d_value)

print(paste("Cohen's d for subject", subject_number, "is", d_value, ". Effect size is", effect_size, "."))


```

Finally, implement the t-calculation as a function. That is, fill in the body of this function (the same limitation that applied to Cohen's d applies here -- you cannot use other packages or R functions like t.test but you can consult AI tools or websites - and again, be careful if you use that, because there are different versions of t-tests):

```{r}

tcalculation <- function(x1, x2) {
  mean_x1 <- mean(x1)
  mean_x2 <- mean(x2)
  se <- sqrt((var(x1) + var(x2)) / length(x1))
  t <- (mean_x1 - mean_x2) / se

}

subject_number <- 15351

words_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter(Subject == subject_number, IsWord == FALSE) %>%
  pull(RT)

t_value <- tcalculation(words_rt, pseudowords_rt)

print(paste("1: T value d for subject", subject_number, "is", t_value, "."))

# T value for all words
words_rt <- merged_data %>%
  filter(IsWord == TRUE) %>%
  pull(RT)

pseudowords_rt <- merged_data %>%
  filter( IsWord == FALSE) %>%
  pull(RT)

t_value <- tcalculation(words_rt, pseudowords_rt)

print(paste("2: T value d for all words is", t_value, "."))

# T value for specified vectors
word_15292 <- c(2206, 1583, 1154, 1010,  865,  931, 1129,  683,  820, 1132, 1049, 1211, 1261, 957, 1058,  790,  851, 1908, 1504, 1400,  924)

pseudoword_15292 <- c(677,  949,  889,  881,  917,  769,  772,  922, 1944,  881,  976, 1087, 1252,  914, 1277,  825, 1295, 1336,  788,  885,  932)

t_value <- tcalculation(word_15292, pseudoword_15292)

print(paste("3: T value d for specified vectors is", t_value, "."))


```

Once the implementation is done, calculate $t$ for:

1. RTs for words and pseudowords for Subject numbered 15351.
2. RTs for all words and pseudowords.
3. RTs for the two vectors provided below as word\_15292 and pseudoword\_15292 (these are a few selected responses to words and pseudowords from subject 15292).

Report the t-values and say briefly why RTs for all words and pseudowords (the second question above) have the highest t-value compared to pseudoword/word\_15292 and compared to the responses of Subject numbered 15351, and why this is not so for Cohen's d. A brief description of the crucial intuition suffices.

*RE: t-value = measure of the difference between group means relative to the variability within the groups => difference in reaction times between all words and pseudowords is much larger compared to the differences observed for Subject 15351 and for the specified vectors. This makes sense since the size of the grouos is much larger for all words and pseudowords, followed by all values for subject 15351 and by the given vectors, that represent just a small part of the values for words and pseudowords from SUbject 15292.
cohen's d = effect size => difference is statistically significant due to the large sample size for all words and pseudowords, but the practical significance is small.
*

### Q3: transforming data and collecting p-values

Based on what we said so far, you should be able to tie t-values that you provided in Q2 to p-values under the null hypothesis that population means between RTs of words and RTs for pseudowords do not differ, i.e., mean(wordRT)=mean(pseudowordRT). Use the t-value from Q2 for the data set word\_15292 and pseudoword\_15292 and use the function *pt* (with degrees of freedom = 40) to provide the answer.

When you are done, come back to one of the assumptions of $t$-probability distributions: t-values are collected from samples of *independent and identically normally distributed data*. We focus on the latter condition. Check if RTs in words and pseudowords are normally distributed. 

If not, try a transformation to get closer to normal distribution. Among transformations, it is common to consider squaring, cubing, taking an inverse, taking square root, or log-transforming data. It is fine if you find only a roughly normal distribution (no testing needed, just checking by observing a histogram is sufficient for this exercise). 

Once you find the best case of transformation, report t-values and p-values for this transformed distribution. You can decide whether you want to use one-tailed or two-tailed tests but whatever you decide, report that.

```{r}

t_15292 <- tcalculation(word_15292, pseudoword_15292)
print(t_15292)

pt(t_15292, df=40)
# not normally distributed
hist(word_15292)
hist(pseudoword_15292)

#square the values - not normal
sqrthist <- sqrt(word_15292)
hist(sqrthist)


#cube the values - not normal
cuberoot = function(x) { 
     if(x < 0)
    { - (-x)^(1/3)}
    else
    {x^(1/3)}
    }
cubelist <- sapply(word_15292, cuberoot) 
print(cubelist)
hist(cubelist)


#inverse the values - NORMAL
inverseList  <- sapply(word_15292, function(x) 1/x)
hist(inverseList)

pseudoinverseList  <- sapply(pseudoword_15292, function(x) 1/x)
hist(inverseList)



#t and p values one-tailed
inverseT <- tcalculation(inverseList, pseudoinverseList)
print(inverseT)
pval <- pt(inverseT, df=40, lower.tail = FALSE)
print(paste("T-value of the inversed data (one-tailed)", as.character(inverseT)))
print(paste("P-value of the inversed data (one-tailed)", as.character(pval)))


```


### Q4: aggregating data

Even if we get a normal distribution of underlying data, we still did not address the issue of independence. Are all RTs in our data set independent?
Clearly not. Participants tend to differ in reaction times from each other and so there will be a dependence in reaction times of each participant. The way to avoid it is to not work with raw data but aggregations. 

Commonly when running a t-test on experimental data, we aggregate the dependent variable, e.g., RTs for words, per participant (that is, we get just one measure per participant, its mean RT over words). We do the same for pseudowords. Then, we calculate the t-value over these aggregated measures and then we calculate p-values. 

Do this for the dataset and report the results. Be careful in thinking about the type of t-test. Is this paired or unpaired?


```{r}
#use a paired t-test
#help of chatGPTG for creating the mean difference function
library(dplyr)

# Custom function for mean difference
mean_difference_function <- function(data) {
  mean_diff <- data$MeanRT[data$IsWord == TRUE] - data$MeanRT[data$IsWord == FALSE]
  return(data.frame(mean_diff = mean_diff))
}

# Apply the custom function for each subject
mean_difference_results <- bySubject_byWord %>%
  group_by(Subject) %>%
  do(mean_difference_function(.))

# Print the results
print(mean_difference_results)


pairedTcalculation <- function(data) {
  n <- length(data) 
  mean_diff <- mean(data$mean_diff)
  sd_diff <- sd(data$mean_diff)
  t_value <- mean_diff / sd_diff / sqrt(n)
  return(t_value)

}


bySubject_byWord <- merged_data  %>%
  group_by(IsWord, Subject) %>%
  summarise(
    MeanRT = mean(RT, na.rm = TRUE),
    SdRT = sd(RT, na.rm = TRUE),
    MinRT = min(RT, na.rm = TRUE),
    MaxRT = max(RT, na.rm = TRUE),
    n = length(RT)
  )


library(dplyr)

normal_words <- bySubject_byWord %>% #this is from chatGPT
  filter(IsWord == TRUE) %>% #this is from chatGPT
  pull(MeanRT) #this is from chatGPT


pseudo_words <- bySubject_byWord %>%
  filter(IsWord == FALSE)%>%
  pull(MeanRT)



aggregratedT <- pairedTcalculation(mean_difference_results)
print(aggregratedT)
aggregatedpval <- pt(aggregratedT, df=220, lower.tail = TRUE)
print(paste("T-value of the aggregrated data (one-tailed)", as.character(aggregratedT)))
print(paste("P-value of the aggregrated data (one-tailed)", as.character(aggregatedpval)))

print(t.test(normal_words, pseudo_words,  paired = TRUE, alternative = "two.sided"))

``` 


### Q6: a pitfall for p-values

Above, we calculated $p$ values based on the assumption that there are 40 degrees of freedom, corresponding to the collection of 42 data points (21 for word\_15292 and 21 for pseudoword\_15292; for each group the degrees of freedom are 21-1, which makes 40 degrees of freedom in total). In a way, we assume that the amount of data points were fixed and it was only open what the values of the data points was.

However, it is quite common that researchers do not know in advance how many participants they want to collect. 
Imagine the following situation: we decided we would be collecting data for the whole day and then we will stop and check the results. It happens so that on that day, there was a 50\% probability that we would collect 12 responses (6 for words, 6 for pseudowords) and a 50\% probability that we would collect 42 data points (21 for words and 21 for pseudowords). In our actual sample, we happened to collect the latter amount (i.e., 42 data points) and we got results as shown in word\_15292 and  pseudoword\_15292. What would \emph{then} be the p-value?

This is probably the most challenging question in this exercise. Here is a hint how to approach it: above (in Section *Using the t-distribution to report p-values*), we saw that you can approximate $t$ distribution using simulation. However, in the case above, we only approximated a $t$ distribution for a single sample, which must have consisted of 20 data points. Here, the situation is more complex for two reasons: (i) we collect two samples and calculate t-values by comparing them, (ii) it is given that the size of the samples is either 12 responses or 42 responses. This will complicate the simulation, but once you create it, you can read off the p-value from it just as we did above.

If you cannot calculate the value, try to at least reason about this: do you think that the p-value will be smaller than in Q4? Or will it be greater? In any case, note one very unintuitive aspect of p-values: they are dependent on experimenters' intentions and hypothetical situations (which might often not be explicitly stated, and might not even be considered!).

### Q7: an experiment where t-tests work

We raised various concerns regarding t-tests. We see that t-tests rely on independence across responses, and they assume that responses are distributed normally. The responses all have to follow the same normal distribution. And we also saw that $p$ values are hard to interpret, they depend on (often unexpressed) intentions of the researcher.

But are there experiments for which t-tests are a great fit?

In this question, try to think of an ``experiment'' data which could appropriately be analyzed by a t-test without any data aggregation. That is, raw data are already suitable for a t-test analysis. Try to describe the experiment in as much detail as possible: what conditions would there be, what variables, which variable would function as a predictor, which should be the outcome variable? Argue why you think t-tests are suitable here (in particular, why you think the data are normal, independent, identically distributed). The word experiment is put in quotes, since you can think of an experiment very broadly - observational studies (like checking a property of houses in a town, or checking some property of students in a class) also qualifies as an experiment.



## Linear models

*This part is easier to answer in the second week of the labs devoted to Assignment 1.*

So far, we worked all the time with RTs split by only one condition: IsWord. In fact, we can study more than one condition. For that, we have to turn to linear regression models. First, consider the following simple model, which only looks at the regression line based on IsWord.

```{r, eval=FALSE}

m1 <- lm(RT ~ IsWord, ...)#put in your data here
print(summary(m1))

```

We can add more parameters and study how they affect the regression line that predicts RTs. For example, the following model would consider the effect of IsWord, Accuracy and their interaction. The * in the notation calculates the main effect of both factors and the interaction of the two factors.

```{r, eval=FALSE}

m2 <- lm(RT ~ IsWord * ACC, ...)#put in your data here
print(summary(m2))

# The * sign signals interaction. See ?formula for details.

```

### Q8: Linear models and graphical representation

Run the models above (m1 and m2). Report results of both of them.

Then, provide a graphical summary accompanying m2. The summary should show how Accuracy and IsWord affect RTs. In your plot we should be able to see differences in the outcomes when the values of the predictor changes. That is, we should be able to see that RTs change when the values of IsWord change, and that RTs change when the values of ACC change, and that IsWord and ACC interact in affecting RTs.

### Q9: What frequency is the best predictor?

There are various sources of frequency in our dataset: FreCOCA, FreqGoogle, FreqSUBTLEX and FreqCOCAspok. These are frequencies of words collected from four different corpora. Find out which of these provides the best fit of the model to the log-transformed reaction times. You can do so by comparing models in which different frequency sources are added, or by comparing how big a proportion of the variance is explained by the model. 

After you find the answer, use the same frequency to address the following observation: it has been claimed that log-frequency of a word is a good predictor, better than a plain frequency, for log-reaction times. Is this correct? Plot the relation between the outcome variable and the non-transformed predictor variable to see whether any clear relation can be observed and whether the relation looks linear. Then, transform the frequency to log and plot again. Then, check the resulting model.

Finally, check whether the log-transformation of all frequency data sets changes your previous answer. Which corpus of frequency is now the best predictor when we consider its log-transformation?

### Q10: Experiment design

You are asked to design an experiment that will test whether log frequency or plain frequency is the right predictor of log reaction times (so, you basically want to test your answer to Q9, but rather than using a corpus data, you want to test your answer in a novel experiment). Your experiment should be a lexical decision task. What will the design be like? Describe (i) the conditions in your experiments, (ii) at least two items in your experiment (these should be words used in the lexical decision task), (iii) what fillers and control items you would use, (iv) how many stimuli would the whole experiment consist of, (v) what log-frequency predicts and what plain frequency predicts as results in your experiment.

## Bibliography

Tucker, Benjamin V, Daniel Brenner, D Kyle Danielson, Matthew C Kelley, Filip Nenadic, and Michelle Sims. 2019.
_The massive auditory lexical decision (MALD) database._ Behavior research methods 51:1187--1204.

